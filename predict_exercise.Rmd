Human Activity Interaction - Exercise Classification
========================================================
Objective of this is to build a model to predict the type of exerciese (classe in the dataset) using data collected from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.

#### Data

Training data set : <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">pml-training.csv</a>

Testing data set : <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">pml-testing.csv</a>

Please refer to  <a href="http://groupware.les.inf.puc-rio.br/har">groupware</a> site for more details which is the source of this data


```{r echo=TRUE}
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(randomForest))
setwd("~/coursera/pml/")
pml <- read.csv("data/pml-training.csv", na.string="#DIV/0!")
pml_names <- names(pml)
testing <- read.csv("data/pml-testing.csv", na.string="#DIV/0!")
predict_columns = c(3:11,37:45,46:49,60:68,84:86,102,113:121,122:124,140,151:159,160)
trainig <- pml[,predict_columns]
```

After analyzing the data set and looking at each variable, following list of variables have been identifed as the predictors. Some of the other variables looks to be more derived from the basic mesured values. Ignored the variables like the user_name, etc

```{r}
pml_names[predict_columns]
```

Let's look at the density plot of the subset of data

```{r fig.width=8,fig.height=6, cache=TRUE}
qplot(classe, data=trainig, geom="density",fill=classe, alpha=I(0.5))
```

It shows, there is a clear pattern in the data set to differentiate the 5 different types of exercise (A,B,C,D,E)

Let us use the random forest to build the classification model. In random forest, there is no need to for cross-validation or a seperate test test to get un biased estimate of the test set error. It is estimated internally.

```{r ecoh=TRUE, cache=TRUE, eval=FALSE}
# Please note building model takes good amout of computer resoruces and takes lot of time
#if you are going to run this locally. please change eval=TRUE
#I have saved the model object and loading in next step below so that there is no need to run the whole model again

modFit1 <- train(classe ~ . , data = training, method = 'rf', trControl = trainControl(method='oob'))
fit <- modFit1$finalModel
```


```{r echo=TRUE,results='asis'}
load("model/fit.rda")
confusion=fit$confusion
sensitivity=(confusion[2,2]/(confusion[2,2]+confusion[2,1]))*100
specificity=(confusion[1,1]/(confusion[1,1]+confusion[1,2]))*100
overall_error=fit$err.rate[length(fit$err.rate[,1]),1]*100
overall_accuracy=1-overall_error
class1_error=paste(rownames(confusion)[1]," error rate= ",confusion[1,3], sep="")
class2_error=paste(rownames(confusion)[2]," error rate= ",confusion[2,3], sep="")
overall_accuracy=100-overall_error
```

Let's look at the random forest model object to understand how the model has performed.

```{r echo=TRUE}
summary(fit)
```

#### Sensitivity = `r sensitivity[1]`
#### Specificity = `r specificity[1]`

#### Overall Error = `r overall_error[1]`
#### Overall Accuracy = `r overall_accuracy[1]` 

Following plot shows importance of variables

```{r echo=TRUE, fig.width=10,fig.height=8}
varImpPlot(fit, type=2, n.var=30, scale=FALSE, main="Variable Importance(Gini) for top 30 predictors")
```

Following plot shows the relation between # of trees and the error. Pelase note that the Error stabilizes after certain # of trees

```{r echo=TRUE, fig.width=6, fig.height=6}
plot(fit,main="Number of trees vs Error")
```
